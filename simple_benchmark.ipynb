{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple GPU/CPU Benchmark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1) # uncomment to run with 1 CPU instead of 16\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1) # uncomment to run with 1 CPU instead of 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2056\n",
    "DATASET_SIZE = 20000\n",
    "DATASET_DIMENSION = 120\n",
    "DATASET_CHANNELS = 3\n",
    "DATASET_SHAPE = (DATASET_SIZE, DATASET_DIMENSION,DATASET_DIMENSION,DATASET_CHANNELS)\n",
    "NUM_CLASSES = 10\n",
    "SPE = 30\n",
    "NUM_EPOCHS = 5\n",
    "NEURONS_PER_LAYER = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthethic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = np.random.rand(DATASET_SIZE, DATASET_DIMENSION, DATASET_DIMENSION, DATASET_CHANNELS)\n",
    "dummy_labels = np.random.randint(NUM_CLASSES, size=DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(batch_size):\n",
    "    dummy_dataset = tf.data.Dataset.from_tensor_slices((dummy_data, dummy_labels))\n",
    "    dummy_dataset = dummy_dataset.prefetch(tf.data.experimental.AUTOTUNE).batch(batch_size).repeat()\n",
    "    return dummy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_hidden_layers):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=(DATASET_DIMENSION, DATASET_DIMENSION, DATASET_CHANNELS)))\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add(keras.layers.Dense(NEURONS_PER_LAYER, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    model = get_model(75)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    start_cpu = time.time()\n",
    "    model.fit(get_dataset(BATCH_SIZE), epochs=NUM_EPOCHS, steps_per_epoch=SPE)\n",
    "    end_cpu = time.time()\n",
    "    time_cpu = end_cpu - start_cpu\n",
    "    print(\"CPU time: {} seconds\".format(time_cpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16 CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    model = get_model(75)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    sixteen_start_cpu = time.time()\n",
    "    model.fit(get_dataset(BATCH_SIZE), epochs=NUM_EPOCHS, steps_per_epoch=SPE)\n",
    "    sixteen_end_cpu = time.time()\n",
    "    sixteen_time_cpu = sixteen_end_cpu - sixteen_start_cpu\n",
    "    print(\"CPU time: {} seconds\".format(sixteen_time_cpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model = get_model(90)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    start_gpu = time.time()\n",
    "    model.fit(get_dataset(BATCH_SIZE), epochs=NUM_EPOCHS, steps_per_epoch=SPE)\n",
    "    end_gpu = time.time()\n",
    "    time_gpu = end_gpu - start_gpu\n",
    "    print(\"GPU time: {} seconds\".format(time_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 GPU (Data Parallel training with All-Reduce Gradient Combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "with mirrored_strategy.scope():\n",
    "    model = get_model(75)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "    start_two_gpu = time.time()\n",
    "    model.fit(get_dataset(BATCH_SIZE), epochs=NUM_EPOCHS, steps_per_epoch=SPE)\n",
    "    end_two_gpu = time.time()\n",
    "    time_two_gpu = end_two_gpu - start_two_gpu\n",
    "    print(\"Two GPU time: {} seconds\".format(time_two_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rcParams['text.latex.preamble']=[r\"\\usepackage{amssymb}\",\n",
    "                                     r\"\\usepackage{amsmath}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 CPU, 5 Layers: 1624 seconds, 15 layers: 2396 seconds,  30 layers: 3583 seconds, 45 layers: 4850 seconds, 60 layers: 6046 seconds, 75 layers: 7311 seconds\n",
    "\n",
    "- 16 CPU: 5 layers: 235 seconds, 15 layers: 337 seconds, 30 layers: 499 seconds, 45 layers: 663 seconds, 60 layers: 830 seconds, 75 layers: 985 seconds\n",
    "\n",
    "- 1 GPU: 5 layers:  95 seconds, 15 layers: 99 seconds , 30 layers: 98 seconds, 45 layers:  116 seconds, 60 layers: 192 seconds, 75 layers: 199 seconds\n",
    "\n",
    "- 2 GPU: 5 layers:  97 seconds, 15 layers: 101 seconds , 30 layers:  109 seconds, 45 layers:  107 seconds, 60 layers: 115 seconds, 75 layers: 181 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {'layers': \n",
    "        ['5 Layers', '15 Layers', '30 Layers', '45 Layers', '60 Layers', '75 Layers'],\n",
    "        '1 Intel Xeon 3.50Ghz': [1624, 2396, 3583, 4850, 6046, 7311],\n",
    "        '16 Intel Xeon 3.50Ghz': [235, 337, 499, 663, 830, 985],\n",
    "        '1 Tesla P100': [95, 99, 98, 116, 192, 199],\n",
    "        '2 Tesla P100': [97, 101, 109, 107, 115, 181]\n",
    "           }\n",
    "df = pd.DataFrame(raw_data, columns = ['layers','1 Intel Xeon 3.50Ghz', '16 Intel Xeon 3.50Ghz', '1 Tesla P100', '2 Tesla P100'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the positions and width for the bars\n",
    "pos = list(range(len(df['1 Intel Xeon 3.50Ghz']))) \n",
    "width = 0.25 \n",
    "    \n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "# Create a bar with pre_score data,\n",
    "# in position pos,\n",
    "plt.bar(pos, \n",
    "        #using df['pre_score'] data,\n",
    "        df['1 Intel Xeon 3.50Ghz'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#EE3224', \n",
    "        # with label the first value in first_name\n",
    "        label=df['layers'][0]) \n",
    "\n",
    "# Create a bar with mid_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width for p in pos], \n",
    "        #using df['mid_score'] data,\n",
    "        df['16 Intel Xeon 3.50Ghz'],\n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#F78F1E', \n",
    "        # with label the second value in first_name\n",
    "        label=df['layers'][1]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*2 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        df['1 Tesla P100'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='#FFC222', \n",
    "        # with label the third value in first_name\n",
    "        label=df['layers'][2]) \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar([p + width*3 for p in pos], \n",
    "        #using df['post_score'] data,\n",
    "        df['2 Tesla P100'], \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.5, \n",
    "        # with color\n",
    "        color='lightblue', \n",
    "        # with label the third value in first_name\n",
    "        label=df['layers'][3]) \n",
    "\n",
    "# Set the y axis label\n",
    "ax.set_ylabel('Time (s)')\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('Deep Learning Hardware Benchmark')\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in pos])\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(df['layers'])\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(pos)-width, max(pos)+width*4)\n",
    "plt.ylim([0, max(df['1 Intel Xeon 3.50Ghz'] + df['16 Intel Xeon 3.50Ghz'] + df['1 Tesla P100'] + df['1 Tesla P100'])] )\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['1 Intel Xeon 3.50Ghz', '16 Intel Xeon 3.50Ghz', '1 Tesla P100', '2 Tesla P100'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.savefig('results.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
